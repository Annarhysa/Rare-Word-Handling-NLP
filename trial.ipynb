{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef Transformer(encodings, batch_choices):\\n    for i, batch_choice in enumerate(batch_choices):\\n        source_sequence = batch_choice.source\\n        target_sequence = batch_choice.target\\n        target_mask = batch_choice.target_mask\\n        \\n        encoded = encoder(source_sequence)  # Pass only the source\\n        decoded = decoder(encoded, target_sequence, target_mask)\\n        context_vector = contextVector(encoded, decoded)  # Adjust this line accordingly\\n        generator_sum_probs = pointerGenerator(context_vector, decoded)  # Adjust this line accordingly\\n        loss = calculateLoss(generator_sum_probs, target_sequence, batch_choice.target)\\n        loss.backward()\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def encoder(input_sequence):\n",
    "    return torch.zeros_like(input_sequence)\n",
    "\n",
    "def decoder(encoder_output, target_input, target_mask):\n",
    "    return torch.zeros_like(encoder_output)\n",
    "\n",
    "def contextVector(encoder_output, multi_head_attn_decoder):\n",
    "    return torch.zeros_like(encoder_output)\n",
    "\n",
    "def pointerGenerator(generator_sum_prob, target_extend_vocab):\n",
    "    return torch.zeros_like(generator_sum_prob)\n",
    "\n",
    "def calculateLoss(generator_sum_probs, target_extended, batch_target):\n",
    "    return torch.tensor(0.0)\n",
    "\n",
    "def Transformer(encodings, batch_choices):\n",
    "    for i, batch_choice in enumerate(batch_choices):\n",
    "        source_sequence = batch_choice.source\n",
    "        target_sequence = batch_choice.target\n",
    "        target_mask = batch_choice.target_mask\n",
    "        \n",
    "        encoded = encoder(source_sequence)  # Pass only the source\n",
    "        decoded = decoder(encoded, target_sequence, target_mask)\n",
    "        context_vector = contextVector(encoded, decoded)  # Adjust this line accordingly\n",
    "        generator_sum_probs = pointerGenerator(context_vector, decoded)  # Adjust this line accordingly\n",
    "        loss = calculateLoss(generator_sum_probs, target_sequence, batch_choice.target)\n",
    "        loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1057,  1012,  1055,  7325,  7319,  2177,  2758,  6263,  2686,\n",
      "          2442, 25729,  1012,  8519,  3160,  8966,  9738,  5128,  5467,  3891,\n",
      "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 10958, 21886,  9600,  1010,  2459,  1010,  2743,  2875,  4176,\n",
      "         11273,  1005,  2651,  3102,  7006,   999,  1005,  7144,  9454,  2879,\n",
      "          6589,  7006, 17539,  9201,  2225,  2634,  1012,   102,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  3224,  5795,  2165,  2280,  3208,  6990, 19560,  2337,  1012,\n",
      "         11331,  3224,  2485,  8402,  8788,  2666, 10650,  2386,  1005,  1055,\n",
      "          3206,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  5658,  2080,  2587, 21554,  8913, 16778,  2532,  6142, 11018,\n",
      "         16132, 28383, 16700,  2249,  1012, 10882,  5686, 16778,  2532,  9653,\n",
      "          5658,  2080,  5799,  6220,  9433,  1012,   102,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  3310, 13463,  5719, 12143,  6653,  2450,  2206,  6624,  9252,\n",
      "          2482,  5823,  2337,  1012,  2425,  1011,  2035,  4357,  4507,  2694,\n",
      "          2732,  1010,  6353,  1010,  2250,  5958,  2258,  2484,  1012,   102,\n",
      "             0,     0],\n",
      "        [  101,  2165,  4073,  2136, 21767,  2663,  2818,  2300,  1012,  5016,\n",
      "         10369,  3062,  5742,  4770,  2188,  3614,  3702,  1010,  7035,  1012,\n",
      "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2779, 19373,  2985,  2702,  2847,  2733, 17372,  2197,  2093,\n",
      "          2706,  2297,  1012,  4481,  2265,  8817,  2145,  8694,  4952,  7820,\n",
      "         19239,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101,  2623,  2265,  6928,  2305,  1036,  1036,  5261,  5035, 10199,\n",
      "          2444,  1005,  1005,  2265,  2709,  2028,  1011,  3178,  2569,  1010,\n",
      "          2628,  6714,  7245,  1010,  2732,  2198,  2358, 22591,  2015,  2758,\n",
      "          1012,   102],\n",
      "        [  101, 23798,  2088,  2528,  2722,  1012,  2128, 20147,  6473,  4320,\n",
      "          6358, 23798,  2088,  2528, 10981,  1012,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [  101, 18421,  3047,  3765,  1010,  5249, 16362,  1005,  5014,  7221,\n",
      "          4917,  1012,  6080, 21278,  2561,  2861,  2086, 12581,  8273,  7741,\n",
      "          2336,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Sample DataFrame\n",
    "data = pd.read_csv('./Data/summarized-data.csv')\n",
    "data = data[:10]\n",
    "\n",
    "# Tokenize and encode the text column\n",
    "encoded_data = tokenizer(data['Summary'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Print the encoded data\n",
    "print(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.BatchChoice object at 0x000001E39FED8F10>, <__main__.BatchChoice object at 0x000001E39D1BC110>, <__main__.BatchChoice object at 0x000001E39FED9210>]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class BatchChoice:\n",
    "    def __init__(self, source, target, target_mask):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.target_mask = target_mask\n",
    "        # Add any other necessary attributes\n",
    "\n",
    "    \n",
    "batch_choices = []\n",
    "for i in range(encoded_data['input_ids'].shape[0]):\n",
    "    source_sequence = encoded_data['input_ids'][i]\n",
    "    target_sequence = encoded_data['input_ids'][i]  # Replace with the actual target tensor\n",
    "    target_mask = encoded_data['attention_mask'][i]\n",
    "    \n",
    "    batch_choice = BatchChoice(source_sequence, target_sequence, target_mask)\n",
    "    batch_choices.append(batch_choice)    \n",
    "\n",
    "print(batch_choices[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformer(encoded_data, batch_choices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
